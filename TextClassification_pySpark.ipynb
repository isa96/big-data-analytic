{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3147664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4ccf1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:25:24 WARN Utils: Your hostname, MacBook-Air-Muhammad.local resolves to a loopback address: 127.0.0.1; using 192.168.43.150 instead (on interface en0)\n",
      "22/03/08 22:25:24 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/08 22:25:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/08 22:25:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"PySparkTextClassifier\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97f22902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('mtsamples.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f35c157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      Type/Specialty|         Sample Name|         Description|          Transcript|            Keywords|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Allergy / Immunology|   Allergic Rhinitis|A 23-year-old whi...|SUBJECTIVE: This ...|allergy / immunol...|\n",
      "|Allergy / Immunology|Allergy Evaluatio...|Acute allergic re...|HISTORY: A 34-yea...|allergy / immunol...|\n",
      "|Allergy / Immunology|Asthma in a 5-yea...|Mother states he ...|\"CHIEF COMPLAINT:...| given the breath...|\n",
      "|Allergy / Immunology|   Chronic Sinusitis|Patient having se...|HISTORY: I had th...|allergy / immunol...|\n",
      "|Allergy / Immunology|Evaluation of All...|Chronic glossitis...|HISTORY: A 55-yea...|allergy / immunol...|\n",
      "|Allergy / Immunology|  Followup on Asthma|A female for a co...|SUBJECTIVE: This ...|allergy / immunol...|\n",
      "|Allergy / Immunology|Kawasaki Disease ...|This is a 14-mont...|ADMITTING DIAGNOS...|allergy / immunol...|\n",
      "|             Autopsy|         Autopsy - 1|Autopsy - Homicid...|EXTERNAL EXAMINAT...|autopsy, black bo...|\n",
      "|             Autopsy|         Autopsy - 2|Autopsy of a whit...|\"CLOTHING: The bo...|            parallel|\n",
      "|             Autopsy|         Autopsy - 3|Autopsy - Asphyxi...|\"EXTERNAL EXAMINA...| consistent with ...|\n",
      "|             Autopsy|         Autopsy - 4|Autopsy - Ligatur...|FINAL DIAGNOSIS: ...|autopsy, ligature...|\n",
      "|             Autopsy|         Autopsy - 5|Autopsy - Homicid...|\"MANNER OF DEATH:...| a pair of blue j...|\n",
      "|             Autopsy|         Autopsy - 6|Multiple sharp fo...|\"ANATOMICAL SUMMA...| visible or morbi...|\n",
      "|             Autopsy|         Autopsy - 7|Cause of death - ...|EXTERNAL EXAMINAT...|autopsy, encephal...|\n",
      "|             Autopsy|         Autopsy - 8|The patient died ...|SUMMARY OF CLINIC...|autopsy, plasmino...|\n",
      "|          Bariatrics|Bariatric Consult...|Evaluation for el...| PAST MEDICAL HIS...|bariatrics, elect...|\n",
      "|          Bariatrics|Bariatric Consult...|Evaluation for el...| PAST MEDICAL HIS...|bariatrics, elect...|\n",
      "|          Bariatrics|Bariatric Consult...|Evaluation for ba...| PAST MEDICAL HIS...|bariatrics, evalu...|\n",
      "|          Bariatrics|Bariatric Consult...|Patient presented...|HISTORY OF PRESEN...|bariatrics, jenny...|\n",
      "|          Bariatrics|Discharge Summary...|Patient suffered ...|ADMISSION DIAGNOS...|bariatrics, lapar...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ef745fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type/Specialty', 'Sample Name', 'Description', 'Transcript', 'Keywords']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ace9bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          Transcript|      Type/Specialty|\n",
      "+--------------------+--------------------+\n",
      "|SUBJECTIVE: This ...|Allergy / Immunology|\n",
      "|HISTORY: A 34-yea...|Allergy / Immunology|\n",
      "|\"CHIEF COMPLAINT:...|Allergy / Immunology|\n",
      "|HISTORY: I had th...|Allergy / Immunology|\n",
      "|HISTORY: A 55-yea...|Allergy / Immunology|\n",
      "|SUBJECTIVE: This ...|Allergy / Immunology|\n",
      "|ADMITTING DIAGNOS...|Allergy / Immunology|\n",
      "|EXTERNAL EXAMINAT...|             Autopsy|\n",
      "|\"CLOTHING: The bo...|             Autopsy|\n",
      "|\"EXTERNAL EXAMINA...|             Autopsy|\n",
      "|FINAL DIAGNOSIS: ...|             Autopsy|\n",
      "|\"MANNER OF DEATH:...|             Autopsy|\n",
      "|\"ANATOMICAL SUMMA...|             Autopsy|\n",
      "|EXTERNAL EXAMINAT...|             Autopsy|\n",
      "|SUMMARY OF CLINIC...|             Autopsy|\n",
      "| PAST MEDICAL HIS...|          Bariatrics|\n",
      "| PAST MEDICAL HIS...|          Bariatrics|\n",
      "| PAST MEDICAL HIS...|          Bariatrics|\n",
      "|HISTORY OF PRESEN...|          Bariatrics|\n",
      "|ADMISSION DIAGNOS...|          Bariatrics|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Transcript','Type/Specialty').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a8bcc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select('Transcript','Type/Specialty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e269e797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|          Transcript|      Type/Specialty|\n",
      "+--------------------+--------------------+\n",
      "|SUBJECTIVE: This ...|Allergy / Immunology|\n",
      "|HISTORY: A 34-yea...|Allergy / Immunology|\n",
      "|\"CHIEF COMPLAINT:...|Allergy / Immunology|\n",
      "|HISTORY: I had th...|Allergy / Immunology|\n",
      "|HISTORY: A 55-yea...|Allergy / Immunology|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d96377aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surgery                          1103\n",
       "Consult - History and Phy.        515\n",
       "Cardiovascular / Pulmonary        372\n",
       "Orthopedic                        357\n",
       "Radiology                         273\n",
       "General Medicine                  258\n",
       "Gastroenterology                  230\n",
       "Neurology                         223\n",
       "SOAP / Chart / Progress Notes     166\n",
       "Obstetrics / Gynecology           160\n",
       "Urology                           158\n",
       "Discharge Summary                 108\n",
       "ENT - Otolaryngology               98\n",
       "Neurosurgery                       94\n",
       "Hematology - Oncology              90\n",
       "Ophthalmology                      83\n",
       "Nephrology                         81\n",
       "Emergency Room Reports             75\n",
       "Pediatrics - Neonatal              70\n",
       "Pain Management                    63\n",
       "Psychiatry / Psychology            53\n",
       "Office Notes                       52\n",
       "Podiatry                           47\n",
       "Dermatology                        30\n",
       "Dentistry                          27\n",
       "Cosmetic / Plastic Surgery         27\n",
       "Letters                            24\n",
       "Physical Medicine - Rehab          21\n",
       "Sleep Medicine                     20\n",
       "Endocrinology                      19\n",
       "Bariatrics                         18\n",
       "IME-QME-Work Comp etc.             16\n",
       "Chiropractic                       14\n",
       "Diets and Nutritions               10\n",
       "Rheumatology                       10\n",
       "Speech - Language                   9\n",
       "Autopsy                             8\n",
       "Lab Medicine - Pathology            8\n",
       "Allergy / Immunology                7\n",
       "Hospice - Palliative Care           6\n",
       "Name: Type/Specialty, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()['Type/Specialty'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4aaef92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()['Type/Specialty'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3cd2a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=('Type/Specialty','Transcript'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d39b90f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toPandas()['Type/Specialty'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f2bd0",
   "metadata": {},
   "source": [
    "## Ekstraksi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88537b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8751ef5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binarizer',\n",
       " 'BucketedRandomProjectionLSH',\n",
       " 'BucketedRandomProjectionLSHModel',\n",
       " 'Bucketizer',\n",
       " 'ChiSqSelector',\n",
       " 'ChiSqSelectorModel',\n",
       " 'CountVectorizer',\n",
       " 'CountVectorizerModel',\n",
       " 'DCT',\n",
       " 'ElementwiseProduct',\n",
       " 'FeatureHasher',\n",
       " 'HasFeaturesCol',\n",
       " 'HasHandleInvalid',\n",
       " 'HasInputCol',\n",
       " 'HasInputCols',\n",
       " 'HasLabelCol',\n",
       " 'HasMaxIter',\n",
       " 'HasNumFeatures',\n",
       " 'HasOutputCol',\n",
       " 'HasOutputCols',\n",
       " 'HasRelativeError',\n",
       " 'HasSeed',\n",
       " 'HasStepSize',\n",
       " 'HasThreshold',\n",
       " 'HasThresholds',\n",
       " 'HashingTF',\n",
       " 'IDF',\n",
       " 'IDFModel',\n",
       " 'Imputer',\n",
       " 'ImputerModel',\n",
       " 'IndexToString',\n",
       " 'Interaction',\n",
       " 'JavaEstimator',\n",
       " 'JavaMLReadable',\n",
       " 'JavaMLWritable',\n",
       " 'JavaModel',\n",
       " 'JavaParams',\n",
       " 'JavaTransformer',\n",
       " 'MaxAbsScaler',\n",
       " 'MaxAbsScalerModel',\n",
       " 'MinHashLSH',\n",
       " 'MinHashLSHModel',\n",
       " 'MinMaxScaler',\n",
       " 'MinMaxScalerModel',\n",
       " 'NGram',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OneHotEncoderModel',\n",
       " 'PCA',\n",
       " 'PCAModel',\n",
       " 'Param',\n",
       " 'Params',\n",
       " 'PolynomialExpansion',\n",
       " 'QuantileDiscretizer',\n",
       " 'RFormula',\n",
       " 'RFormulaModel',\n",
       " 'RegexTokenizer',\n",
       " 'RobustScaler',\n",
       " 'RobustScalerModel',\n",
       " 'SQLTransformer',\n",
       " 'SparkContext',\n",
       " 'StandardScaler',\n",
       " 'StandardScalerModel',\n",
       " 'StopWordsRemover',\n",
       " 'StringIndexer',\n",
       " 'StringIndexerModel',\n",
       " 'Tokenizer',\n",
       " 'TypeConverters',\n",
       " 'UnivariateFeatureSelector',\n",
       " 'UnivariateFeatureSelectorModel',\n",
       " 'VarianceThresholdSelector',\n",
       " 'VarianceThresholdSelectorModel',\n",
       " 'VectorAssembler',\n",
       " 'VectorIndexer',\n",
       " 'VectorIndexerModel',\n",
       " 'VectorSizeHint',\n",
       " 'VectorSlicer',\n",
       " 'Word2Vec',\n",
       " 'Word2VecModel',\n",
       " '_BucketedRandomProjectionLSHParams',\n",
       " '_CountVectorizerParams',\n",
       " '_IDFParams',\n",
       " '_ImputerParams',\n",
       " '_LSH',\n",
       " '_LSHModel',\n",
       " '_LSHParams',\n",
       " '_MaxAbsScalerParams',\n",
       " '_MinMaxScalerParams',\n",
       " '_OneHotEncoderParams',\n",
       " '_PCAParams',\n",
       " '_RFormulaParams',\n",
       " '_RobustScalerParams',\n",
       " '_Selector',\n",
       " '_SelectorModel',\n",
       " '_SelectorParams',\n",
       " '_StandardScalerParams',\n",
       " '_StringIndexerParams',\n",
       " '_UnivariateFeatureSelectorParams',\n",
       " '_VarianceThresholdSelectorParams',\n",
       " '_VectorIndexerParams',\n",
       " '_Word2VecParams',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_convert_to_vector',\n",
       " '_jvm',\n",
       " 'inherit_doc',\n",
       " 'keyword_only',\n",
       " 'since']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61efa3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c61095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stages for the Pipeline\n",
    "tokenizer = Tokenizer(inputCol='Transcript', outputCol='mytokens')\n",
    "stopwords_remover = StopWordsRemover(inputCol='mytokens', outputCol='filtered_tokens')\n",
    "vectorizer = CountVectorizer(inputCol='filtered_tokens', outputCol='rawFeatures')\n",
    "idf = IDF(inputCol='rawFeatures', outputCol='vectorizedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3874ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoding/LabelIndexing\n",
    "labelEncoder = StringIndexer(inputCol='Type/Specialty', outputCol='label').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8288f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|          Transcript|      Type/Specialty|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|SUBJECTIVE: This ...|Allergy / Immunology| 38.0|\n",
      "|HISTORY: A 34-yea...|Allergy / Immunology| 38.0|\n",
      "|\"CHIEF COMPLAINT:...|Allergy / Immunology| 38.0|\n",
      "|HISTORY: I had th...|Allergy / Immunology| 38.0|\n",
      "|HISTORY: A 55-yea...|Allergy / Immunology| 38.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelEncoder.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c721f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Surgery',\n",
       " 'Consult - History and Phy.',\n",
       " 'Cardiovascular / Pulmonary',\n",
       " 'Orthopedic',\n",
       " 'Radiology',\n",
       " 'General Medicine',\n",
       " 'Gastroenterology',\n",
       " 'Neurology',\n",
       " 'SOAP / Chart / Progress Notes',\n",
       " 'Urology',\n",
       " 'Obstetrics / Gynecology',\n",
       " 'Discharge Summary',\n",
       " 'ENT - Otolaryngology',\n",
       " 'Neurosurgery',\n",
       " 'Hematology - Oncology',\n",
       " 'Ophthalmology',\n",
       " 'Nephrology',\n",
       " 'Emergency Room Reports',\n",
       " 'Pediatrics - Neonatal',\n",
       " 'Pain Management',\n",
       " 'Psychiatry / Psychology',\n",
       " 'Office Notes',\n",
       " 'Podiatry',\n",
       " 'Dermatology',\n",
       " 'Cosmetic / Plastic Surgery',\n",
       " 'Dentistry',\n",
       " 'Letters',\n",
       " 'Physical Medicine - Rehab',\n",
       " 'Sleep Medicine',\n",
       " 'Endocrinology',\n",
       " 'Bariatrics',\n",
       " 'IME-QME-Work Comp etc.',\n",
       " 'Chiropractic',\n",
       " 'Diets and Nutritions',\n",
       " 'Rheumatology',\n",
       " 'Speech - Language',\n",
       " 'Autopsy',\n",
       " 'Lab Medicine - Pathology',\n",
       " 'Allergy / Immunology',\n",
       " 'Hospice - Palliative Care']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEncoder.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3554b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|          Transcript|      Type/Specialty|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|SUBJECTIVE: This ...|Allergy / Immunology| 38.0|\n",
      "|HISTORY: A 34-yea...|Allergy / Immunology| 38.0|\n",
      "|\"CHIEF COMPLAINT:...|Allergy / Immunology| 38.0|\n",
      "|HISTORY: I had th...|Allergy / Immunology| 38.0|\n",
      "|HISTORY: A 55-yea...|Allergy / Immunology| 38.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = labelEncoder.transform(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec7b6a8",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02335eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainDF, testDF) = df.randomSplit((0.8,0.2), seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75bf8a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|          Transcript|      Type/Specialty|label|\n",
      "+--------------------+--------------------+-----+\n",
      "| 1. The left vent...|Cardiovascular / ...|  2.0|\n",
      "| Assessment for p...|Consult - History...|  1.0|\n",
      "| CLINICAL INDICAT...|Cardiovascular / ...|  2.0|\n",
      "| COMPARISON STUDI...|Cardiovascular / ...|  2.0|\n",
      "| COMPARISON: None...|Cardiovascular / ...|  2.0|\n",
      "| Dear Sample Doct...|Cardiovascular / ...|  2.0|\n",
      "| FAMILY HISTORY: ...|Consult - History...|  1.0|\n",
      "| FAMILY HISTORY: ...|Consult - History...|  1.0|\n",
      "| FINDINGS: Normal...|        Chiropractic| 32.0|\n",
      "| GENERAL: Negativ...|Consult - History...|  1.0|\n",
      "| HISTORY OF PRESE...|Consult - History...|  1.0|\n",
      "| HISTORY OF PRESE...|Consult - History...|  1.0|\n",
      "| HISTORY OF PRESE...|Consult - History...|  1.0|\n",
      "| He has no voidin...|Consult - History...|  1.0|\n",
      "| Her axial back p...|Consult - History...|  1.0|\n",
      "| Informed written...|Cardiovascular / ...|  2.0|\n",
      "| Mr. XYZ forgot h...|        Chiropractic| 32.0|\n",
      "| Mr. XYZ forgot h...|Consult - History...|  1.0|\n",
      "| PAST MEDICAL HIS...|Consult - History...|  1.0|\n",
      "| PAST MEDICAL HIS...|          Bariatrics| 30.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4735eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol='vectorizedFeatures', labelCol='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79031964",
   "metadata": {},
   "source": [
    "## Membuat Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a5608b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Param(parent='Pipeline_c45dbcafe8bd', name='stages', doc='a list of pipeline stages')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stopwords_remover, vectorizer, idf, lr])\n",
    "pipeline.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fbd011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:36:47 WARN DAGScheduler: Broadcasting large task binary with size 1199.4 KiB\n",
      "22/03/08 22:36:49 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:36:50 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/03/08 22:36:50 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/03/08 22:36:51 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/03/08 22:36:51 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "22/03/08 22:36:52 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:36:53 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:36:54 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:36:56 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:36:57 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:36:59 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:00 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:02 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:03 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:05 WARN BlockManager: Asked to remove block broadcast_94_piece0, which does not exist\n",
      "22/03/08 22:37:05 WARN BlockManager: Asked to remove block broadcast_94, which does not exist\n",
      "22/03/08 22:37:05 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:07 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:09 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:11 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:13 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:15 WARN BlockManager: Asked to remove block broadcast_104_piece3, which does not exist\n",
      "22/03/08 22:37:15 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:17 WARN BlockManager: Asked to remove block broadcast_106_piece3, which does not exist\n",
      "22/03/08 22:37:17 WARN BlockManager: Asked to remove block broadcast_106_piece0, which does not exist\n",
      "22/03/08 22:37:17 WARN BlockManager: Asked to remove block broadcast_106_piece2, which does not exist\n",
      "22/03/08 22:37:17 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:20 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:22 WARN BlockManager: Asked to remove block broadcast_110_piece2, which does not exist\n",
      "22/03/08 22:37:22 WARN BlockManager: Asked to remove block broadcast_110, which does not exist\n",
      "22/03/08 22:37:22 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:24 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:26 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:28 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:30 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:32 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:34 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:37 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:38 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:41 WARN BlockManager: Asked to remove block broadcast_128_piece1, which does not exist\n",
      "22/03/08 22:37:41 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:43 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:45 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:47 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:49 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:51 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:53 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:55 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:37:58 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:00 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:02 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:04 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:06 WARN BlockManager: Asked to remove block broadcast_152_piece1, which does not exist\n",
      "22/03/08 22:38:06 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:09 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:11 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:13 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:15 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:17 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:19 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:21 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:23 WARN BlockManager: Asked to remove block broadcast_168_piece0, which does not exist\n",
      "22/03/08 22:38:23 WARN BlockManager: Asked to remove block broadcast_168_piece2, which does not exist\n",
      "22/03/08 22:38:23 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:25 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:27 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:30 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:32 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:34 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:36 WARN BlockManager: Asked to remove block broadcast_180_piece3, which does not exist\n",
      "22/03/08 22:38:36 WARN BlockManager: Asked to remove block broadcast_180, which does not exist\n",
      "22/03/08 22:38:36 WARN BlockManager: Asked to remove block broadcast_180_piece2, which does not exist\n",
      "22/03/08 22:38:36 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:39 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:41 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:43 WARN BlockManager: Asked to remove block broadcast_186_piece3, which does not exist\n",
      "22/03/08 22:38:43 WARN BlockManager: Asked to remove block broadcast_186, which does not exist\n",
      "22/03/08 22:38:43 WARN BlockManager: Asked to remove block broadcast_186_piece0, which does not exist\n",
      "22/03/08 22:38:43 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:46 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:48 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:50 WARN BlockManager: Asked to remove block broadcast_192, which does not exist\n",
      "22/03/08 22:38:50 WARN BlockManager: Asked to remove block broadcast_192_piece3, which does not exist\n",
      "22/03/08 22:38:50 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:52 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:54 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:56 WARN BlockManager: Asked to remove block broadcast_198_piece1, which does not exist\n",
      "22/03/08 22:38:56 WARN BlockManager: Asked to remove block broadcast_198, which does not exist\n",
      "22/03/08 22:38:56 WARN BlockManager: Asked to remove block broadcast_198_piece2, which does not exist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:38:56 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:38:58 WARN BlockManager: Asked to remove block broadcast_200_piece0, which does not exist\n",
      "22/03/08 22:38:58 WARN BlockManager: Asked to remove block broadcast_200_piece3, which does not exist\n",
      "22/03/08 22:38:58 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:00 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:02 WARN BlockManager: Asked to remove block broadcast_204, which does not exist\n",
      "22/03/08 22:39:02 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:05 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:06 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:09 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:11 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:13 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:15 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:17 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:19 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:21 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:23 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:26 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:28 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:30 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:32 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:34 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:36 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:38 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:40 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:42 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:44 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:46 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:48 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:50 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:53 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:55 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:57 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:39:59 WARN BlockManager: Asked to remove block broadcast_258, which does not exist\n",
      "22/03/08 22:39:59 WARN BlockManager: Asked to remove block broadcast_258_piece1, which does not exist\n",
      "22/03/08 22:39:59 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:02 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:04 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:06 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:08 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:10 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:12 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:14 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:16 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:18 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:21 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:23 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:25 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:27 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:29 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:31 WARN DAGScheduler: Broadcasting large task binary with size 1201.0 KiB\n",
      "22/03/08 22:40:33 WARN BlockManager: Asked to remove block broadcast_290_piece1, which does not exist\n",
      "22/03/08 22:40:33 WARN BlockManager: Asked to remove block broadcast_290, which does not exist\n"
     ]
    }
   ],
   "source": [
    "lr_model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "612c4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9baf076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:40:35 WARN DAGScheduler: Broadcasting large task binary with size 14.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|          Transcript|      Type/Specialty|label|            mytokens|     filtered_tokens|         rawFeatures|  vectorizedFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| CARDIAC CT INCLU...|Cardiovascular / ...|  2.0|[, cardiac, ct, i...|[, cardiac, ct, i...|(42448,[0,1,2,4,7...|(42448,[0,1,2,4,7...|[1.37357286547299...|[6.64410482890758...|       4.0|\n",
      "| CURRENT MEDICATI...|Consult - History...|  1.0|[, current, medic...|[, current, medic...|(42448,[0,3,4,5,7...|(42448,[0,3,4,5,7...|[-11.591020538496...|[9.62096125133030...|      35.0|\n",
      "| FAMILY HISTORY A...|Consult - History...|  1.0|[, family, histor...|[, family, histor...|(42448,[1,2,5,12,...|(42448,[1,2,5,12,...|[-16.615346613270...|[1.67577407801782...|       7.0|\n",
      "| Grade II: Athero...|Cardiovascular / ...|  2.0|[, grade, ii:, at...|[, grade, ii:, at...|(42448,[1,2,12,35...|(42448,[1,2,12,35...|[0.39570704907001...|[1.18529694810317...|       4.0|\n",
      "| Her past medical...|Consult - History...|  1.0|[, her, past, med...|[, past, medical,...|(42448,[1,2,4,5,1...|(42448,[1,2,4,5,1...|[-6.3730262430060...|[5.31763463723151...|      15.0|\n",
      "| PAST MEDICAL HIS...|          Bariatrics| 30.0|[, past, medical,...|[, past, medical,...|(42448,[1,12,13,1...|(42448,[1,12,13,1...|[-25.106198259531...|[2.86289491452228...|       1.0|\n",
      "| PAST MEDICAL HIS...|Consult - History...|  1.0|[, past, medical,...|[, past, medical,...|(42448,[0,1,2,5,1...|(42448,[0,1,2,5,1...|[-15.226143729731...|[7.10923176821287...|      30.0|\n",
      "| PAST MEDICAL HIS...|Consult - History...|  1.0|[, past, medical,...|[, past, medical,...|(42448,[0,1,5,6,1...|(42448,[0,1,5,6,1...|[-21.618803906949...|[1.20840240128389...|      30.0|\n",
      "| SOCIAL HISTORY, ...|Consult - History...|  1.0|[, social, histor...|[, social, histor...|(42448,[0,2,4,13,...|(42448,[0,2,4,13,...|[-6.7526618506027...|[2.62896199017739...|       7.0|\n",
      "| She has a past o...|Consult - History...|  1.0|[, she, has, a, p...|[, past, ocular, ...|(42448,[1,2,4,5,6...|(42448,[1,2,4,5,6...|[-11.102161473371...|[7.8365916467344E...|      15.0|\n",
      "| She started her ...|Consult - History...|  1.0|[, she, started, ...|[, started, perio...|(42448,[1,2,4,5,6...|(42448,[1,2,4,5,6...|[-25.721555600163...|[1.64946175121761...|      10.0|\n",
      "| The patient stat...|Consult - History...|  1.0|[, the, patient, ...|[, patient, state...|(42448,[0,4,5,8,9...|(42448,[0,4,5,8,9...|[-23.058384014694...|[1.85785208425831...|      10.0|\n",
      "| We discovered ne...|Cardiovascular / ...|  2.0|[, we, discovered...|[, discovered, ne...|(42448,[8,9,11,12...|(42448,[8,9,11,12...|[-4.8466387798778...|[1.95894744059946...|      11.0|\n",
      "|\" HISTORY OF PRES...|Consult - History...|  1.0|[\", history, of, ...|[\", history, pres...|(42448,[0,1,4,5,6...|(42448,[0,1,4,5,6...|[-11.360239343837...|[4.50878589754536...|      17.0|\n",
      "|\" Subsequently, t...|Consult - History...|  1.0|[\", subsequently,...|[\", subsequently,...|(42448,[0,5,11,13...|(42448,[0,5,11,13...|[-12.212404422195...|[3.43977422482677...|       7.0|\n",
      "|\"CC: \"\"Five years...|Consult - History...|  1.0|[\"cc:, \"\"five, ye...|[\"cc:, \"\"five, ye...|(42448,[282,683,2...|(42448,[282,683,2...|[2.41274732670257...|[3.98047188702480...|      20.0|\n",
      "|\"CC: Headache and...|Consult - History...|  1.0|[\"cc:, headache, ...|[\"cc:, headache, ...|(42448,[0,1,18,55...|(42448,[0,1,18,55...|[-4.1292250242368...|[5.91900432961935...|       7.0|\n",
      "|\"CHIEF COMPLAINT:...|Consult - History...|  1.0|[\"chief, complain...|[\"chief, complain...|(42448,[0,5,12,13...|(42448,[0,5,12,13...|[-5.7481063103309...|[9.82866036886265...|       6.0|\n",
      "|\"GROSS DESCRIPTIO...|Cardiovascular / ...|  2.0|[\"gross, descript...|[\"gross, descript...|(42448,[28,48,53,...|(42448,[28,48,53,...|[-0.5196028408638...|[8.11039041282563...|      37.0|\n",
      "|\"HISTORY OF PRESE...|Consult - History...|  1.0|[\"history, of, pr...|[\"history, presen...|(42448,[0,4,5,6,7...|(42448,[0,4,5,6,7...|[23.0978509800339...|[0.50015112558574...|       0.0|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "503c1e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transcript',\n",
       " 'Type/Specialty',\n",
       " 'label',\n",
       " 'mytokens',\n",
       " 'filtered_tokens',\n",
       " 'rawFeatures',\n",
       " 'vectorizedFeatures',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "566fba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:40:36 WARN DAGScheduler: Broadcasting large task binary with size 14.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|       rawPrediction|         probability|      Type/Specialty|label|prediction|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|[1.37357286547299...|[6.64410482890758...|Cardiovascular / ...|  2.0|       4.0|\n",
      "|[-11.591020538496...|[9.62096125133030...|Consult - History...|  1.0|      35.0|\n",
      "|[-16.615346613270...|[1.67577407801782...|Consult - History...|  1.0|       7.0|\n",
      "|[0.39570704907001...|[1.18529694810317...|Cardiovascular / ...|  2.0|       4.0|\n",
      "|[-6.3730262430060...|[5.31763463723151...|Consult - History...|  1.0|      15.0|\n",
      "|[-25.106198259531...|[2.86289491452228...|          Bariatrics| 30.0|       1.0|\n",
      "|[-15.226143729731...|[7.10923176821287...|Consult - History...|  1.0|      30.0|\n",
      "|[-21.618803906949...|[1.20840240128389...|Consult - History...|  1.0|      30.0|\n",
      "|[-6.7526618506027...|[2.62896199017739...|Consult - History...|  1.0|       7.0|\n",
      "|[-11.102161473371...|[7.8365916467344E...|Consult - History...|  1.0|      15.0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('rawPrediction',\n",
    " 'probability','Type/Specialty','label',\n",
    " 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5780a",
   "metadata": {},
   "source": [
    "### Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6c91724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3be9a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14fc7871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:41:18 WARN DAGScheduler: Broadcasting large task binary with size 14.1 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "541f61f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1078838174273859"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5f115e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0336fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhihsan/miniconda3/envs/kuliah/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "22/03/08 22:41:49 WARN DAGScheduler: Broadcasting large task binary with size 14.1 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_metric = MulticlassMetrics(predictions['label','prediction'].rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f62e0f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:41:56 WARN DAGScheduler: Broadcasting large task binary with size 14.1 MiB\n",
      "[Stage 156:>                                                        (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.1078838174273859\n",
      "Precision:  0.13095238095238096\n",
      "Recall:  0.08661417322834646\n",
      "F1Score:  0.1042654028436019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', lr_metric.accuracy)\n",
    "print('Precision: ', lr_metric.precision(1.0))\n",
    "print('Recall: ', lr_metric.recall(1.0))\n",
    "print('F1Score: ', lr_metric.fMeasure(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039d1998",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a8b10f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/08 22:42:32 WARN DAGScheduler: Broadcasting large task binary with size 14.1 MiB\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select('label')\n",
    "y_true = y_true.toPandas()\n",
    "y_pred = predictions.select('prediction')\n",
    "y_pred = y_pred.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f0c5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36b3918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bcd8a56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[43,  0, 21, ...,  0,  0,  0],\n",
       "       [ 1, 11,  3, ...,  1,  0,  0],\n",
       "       [25, 11,  9, ...,  0,  2,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  2, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9bb9ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d6520b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.18      0.20      0.19       211\n",
      "         1.0       0.09      0.13      0.10        84\n",
      "         2.0       0.13      0.13      0.13        67\n",
      "         3.0       0.09      0.07      0.08        73\n",
      "         4.0       0.12      0.11      0.12        63\n",
      "         5.0       0.07      0.07      0.07        45\n",
      "         6.0       0.09      0.09      0.09        43\n",
      "         7.0       0.02      0.02      0.02        41\n",
      "         8.0       0.04      0.03      0.03        38\n",
      "         9.0       0.06      0.06      0.06        34\n",
      "        10.0       0.03      0.03      0.03        29\n",
      "        11.0       0.08      0.09      0.09        23\n",
      "        12.0       0.06      0.06      0.06        16\n",
      "        13.0       0.00      0.00      0.00        14\n",
      "        14.0       0.05      0.04      0.05        24\n",
      "        15.0       0.17      0.14      0.15        21\n",
      "        16.0       0.11      0.06      0.08        17\n",
      "        17.0       0.00      0.00      0.00        15\n",
      "        18.0       0.00      0.00      0.00        16\n",
      "        19.0       0.67      0.44      0.53         9\n",
      "        20.0       0.20      0.18      0.19        11\n",
      "        21.0       0.00      0.00      0.00        12\n",
      "        22.0       0.14      0.09      0.11        11\n",
      "        23.0       0.00      0.00      0.00         5\n",
      "        24.0       0.00      0.00      0.00         4\n",
      "        25.0       0.00      0.00      0.00         2\n",
      "        26.0       0.10      0.33      0.15         3\n",
      "        27.0       0.00      0.00      0.00         7\n",
      "        28.0       1.00      0.17      0.29         6\n",
      "        29.0       0.00      0.00      0.00         4\n",
      "        30.0       0.00      0.00      0.00         3\n",
      "        31.0       0.00      0.00      0.00         4\n",
      "        32.0       0.00      0.00      0.00         1\n",
      "        33.0       0.00      0.00      0.00         1\n",
      "        34.0       0.00      0.00      0.00         1\n",
      "        35.0       0.00      0.00      0.00         1\n",
      "        37.0       0.00      0.00      0.00         3\n",
      "        38.0       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.11       964\n",
      "   macro avg       0.09      0.07      0.07       964\n",
      "weighted avg       0.11      0.11      0.11       964\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhihsan/miniconda3/envs/kuliah/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mhihsan/miniconda3/envs/kuliah/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mhihsan/miniconda3/envs/kuliah/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144dc75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kuliah]",
   "language": "python",
   "name": "conda-env-kuliah-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
